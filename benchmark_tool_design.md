# Go Benchmark Tool for gRPC Key-Value Store

## ðŸ“Œ Objective

Design a high-performance, configurable, and extensible benchmark tool to evaluate the performance of a gRPC-based Key-Value store backed by SPDK or kernel block device. The tool will simulate concurrent client workloads with tunable operation mix and measure latency, throughput, and error rates.

---

## ðŸ§± Architecture Overview

```
                 +------------------+
                 |  CLI / Config    |
                 +--------+---------+
                          |
                          v
                 +--------+--------+
                 |  BenchmarkRunner |
                 +--------+--------+
                          |
        +-----------------+------------------+
        |                |                  |
        v                v                  v
   +----+----+      +----+----+        +----+----+
   | Worker 1 | ...  | Worker N |  ...  | Collector|
   +----+----+      +----+----+        +----+----+
        |                |                  ^
        v                v                  |
   [gRPC Client]    [gRPC Client]    <--  Results Channel
```

---

## âš™ï¸ Configuration

All benchmark parameters are controlled via the `BenchmarkConfig` struct or via CLI flags / JSON.

### `BenchmarkConfig`

```go
type BenchmarkConfig struct {
    TargetAddress   string        // gRPC server (e.g., "localhost:50051")
    NumConnections  int           // Number of gRPC connections
    NumWorkers      int           // Total concurrent goroutines
    Duration        time.Duration // Benchmark duration
    WarmupDuration  time.Duration // Optional warm-up before measurement
    KeySpace        int           // Unique keys to use
    ValueSize       int           // Size of values in bytes
    ReadRatio       int           // % of Get requests
    WriteRatio      int           // % of Put requests
    DeleteRatio     int           // % of Delete requests
    ReportInterval  time.Duration // Intermediate stats print interval
    OutputCSV       string        // Path to save final results
    LogRequests     bool          // Whether to log all requests
    LogErrors       bool          // Whether to log only failed requests
}
```

---

## ðŸ”Œ Connections

- Create a pool of persistent `grpc.ClientConn` (length = `NumConnections`)
- Each worker selects a connection (round-robin or random) to spread load

---

## ðŸš€ Workers

- Spawn `NumWorkers` goroutines
- Each worker:
  - Picks an operation (`Get`, `Put`, `Delete`) based on configured ratio
  - Picks a key from a pre-generated pool of `KeySpace` entries
  - Generates a value (for `Put`)
  - Issues gRPC request
  - Measures latency
  - Reports result to collector

---

## ðŸ§  Key/Value Handling

- Pre-generate `KeySpace` keys
- Use base64/random 8â€“16 byte strings for keys
- For `Put`, generate `ValueSize` byte values per request

---

## ðŸ“Š Result Reporting

### `BenchmarkResult`

```go
type BenchmarkResult struct {
    Method    string
    LatencyMs float64
    Error     error
    Timestamp time.Time
}
```

- All results sent to a buffered `results` channel
- Aggregator/Collector computes:
  - Ops/sec (RPS)
  - Average, P50, P95, P99 latency
  - Error counts
  - Writes to CSV if configured
  - Logs requests/errors if enabled in config

---

## ðŸ“„ Code Structure

```
cmd/
â””â”€â”€ benchmarker/
    â””â”€â”€ main.go           â†’ CLI entrypoint
pkg/
â”œâ”€â”€ runner/
â”‚   â”œâ”€â”€ runner.go         â†’ Runs workers, manages connections
â”‚   â””â”€â”€ keygen.go         â†’ Key/value generator utilities
â”œâ”€â”€ kvclient/
â”‚   â””â”€â”€ client.go         â†’ Wrapper over gRPC kvstore client
â”œâ”€â”€ collector/
â”‚   â””â”€â”€ collector.go      â†’ Result aggregator and reporter
â””â”€â”€ config/
    â””â”€â”€ config.go         â†’ Config parsing (JSON or flags)

internal/
â””â”€â”€ proto/
    â””â”€â”€ kvstore.pb.go     â†’ gRPC client interface
```

---

## ðŸ“ˆ Metrics Collected

| Metric             | Description                              |
| ------------------ | ---------------------------------------- |
| Ops/sec (RPS)      | Throughput per method & overall          |
| Latency            | P50, P95, P99, max, avg (ms)             |
| Error Rate         | % of failed requests                     |
| Success Count      | Total completed requests                 |
| CSV Output         | Per-request latency + timestamp          |
| Request/Error Logs | Raw gRPC request or failure (if enabled) |

---

## ðŸ§ª Sample Output (Console)

```
[5s] Total: 15,000 | RPS: 3,000 | Avg Latency: 2.5ms | P95: 4.3ms | Errors: 0
[10s] Total: 30,200 | RPS: 3,020 | Avg Latency: 2.6ms | P95: 4.2ms | Errors: 3
```

---

## ðŸ§  Extensibility Ideas

- Support **TLS** and **auth token**
- Add **histogram visualizer**
- Export to **Prometheus**
- Support **multi-host** testing
- **Ramp-up phase** before measuring
- **Multiple key spaces / prefixes** for simulating multi-tenant behavior

---

## ðŸš¡ Best Practices

- Pin CPU affinity for SPDK tests
- Always preload keys before benchmark
- Disable console logging from server to reduce noise
- Warm-up the system for 5â€“10 seconds before actual measurement
- Always compare SPDK vs kernel with same thread count & hardware

---

## ðŸ Example Command

```bash
go run main.go \
  --target=127.0.0.1:50051 \
  --connections=8 \
  --workers=100 \
  --duration=30s \
  --warmup=5s \
  --keyspace=50000 \
  --valuesize=1024 \
  --read=70 --write=25 --delete=5 \
  --log-requests \
  --log-errors \
  --csv=results/spdk_2025-07-02.csv
```

---

## âœ… Milestones

1. âœ… Define config and CLI
2. âœ… Implement connection pool and clients
3. âœ… Worker logic for random ops
4. âœ… Latency tracking and collector
5. âœ… CSV & live console reporting
6. âœ… Run with both SPDK and kernel backends

